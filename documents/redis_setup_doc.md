# ‚ö° Redis Setup - B-CraftD v3.0

**Date** : 4 d√©cembre 2025  
**Version** : 3.0.0  
**Statut** : ‚úÖ Configuration compl√®te avec Docker

---

## üéØ Objectif

Configurer Redis comme **cache temps r√©el** pour :
- ‚ö° **Environnement** (m√©t√©o, saison) - TTL 1h
- ‚ö° **Listings march√© actifs** - TTL 1min
- ‚ö° **Leaderboard** - TTL 5min
- ‚ö° **Inventaires utilisateurs** - TTL 30s
- ‚ö° **Sessions utilisateurs** - TTL 24h
- ‚ö° **Rate limiting API** - Fen√™tres variables

**Gains attendus** :
- -70% requ√™tes PostgreSQL
- -30% temps r√©ponse API
- +500% capacit√© utilisateurs simultan√©s

---

## üì¶ Installation avec Docker

### M√©thode 1 : Docker Compose (Recommand√©)

**Fichier : `docker-compose.yml`** (d√©j√† cr√©√©)

```bash
# D√©marrer tous les services (PostgreSQL + MongoDB + Redis)
docker-compose up -d

# D√©marrer uniquement Redis
docker-compose up -d redis

# V√©rifier les logs
docker-compose logs -f redis

# Arr√™ter
docker-compose down

# Arr√™ter et supprimer les volumes
docker-compose down -v
```

### M√©thode 2 : Docker Run (Manuel)

```bash
# Cr√©er volume persistant
docker volume create redis_data

# Lancer Redis avec mot de passe
docker run -d \
  --name bcraftd-redis \
  -p 6379:6379 \
  -v redis_data:/data \
  -v $(pwd)/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro \
  --network bcraftd-network \
  redis:7.2-alpine \
  redis-server /usr/local/etc/redis/redis.conf --requirepass redis_secure_pass

# V√©rifier le statut
docker ps | grep redis

# Acc√©der au CLI
docker exec -it bcraftd-redis redis-cli -a redis_secure_pass
```

### M√©thode 3 : Installation Native (Sans Docker)

#### Ubuntu/Debian
```bash
# Ajouter repository Redis
curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg

echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/redis.list

# Installer Redis
sudo apt update
sudo apt install redis -y

# D√©marrer
sudo systemctl start redis-server
sudo systemctl enable redis-server

# V√©rifier
redis-cli ping
# PONG
```

#### macOS
```bash
brew install redis
brew services start redis
```

---

## üîß Configuration

### Fichier redis.conf

Plac√© dans `redis/redis.conf` (configuration optimis√©e B-CraftD) :

```conf
# Persistence hybride (RDB + AOF)
save 900 1
save 300 10
save 60 10000
appendonly yes
appendfsync everysec

# M√©moire
maxmemory 512mb
maxmemory-policy allkeys-lru

# Performance
io-threads 4
io-threads-do-reads yes

# S√©curit√©
requirepass redis_secure_pass
timeout 300

# Notifications (pour invalidation cache)
notify-keyspace-events "Ex"
```

### Variables d'Environnement (.env)

```bash
REDIS_PASSWORD=redis_secure_pass_change_me
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_URI=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}

# TTL Configuration
CACHE_ENVIRONMENT_TTL=3600
CACHE_MARKET_LISTINGS_TTL=60
CACHE_LEADERBOARD_TTL=300
CACHE_USER_INVENTORY_TTL=30
```

### D√©pendances Python

```bash
pip install redis==5.0.1
pip install pytest==7.4.3  # Pour tests
```

---

## üöÄ Utilisation du CacheService

### Initialisation

```python
from services.cache_service import CacheService

# Depuis variables d'environnement
import os

cache = CacheService(
    host=os.getenv("REDIS_HOST", "localhost"),
    port=int(os.getenv("REDIS_PORT", 6379)),
    password=os.getenv("REDIS_PASSWORD"),
    db=int(os.getenv("REDIS_DB", 0)),
    max_connections=50
)
```

### 1. Cache Environnement

```python
# Route: GET /api/environment/current
@router.get("/current")
def get_current_environment(cache: CacheService = Depends(get_cache)):
    # V√©rifier cache
    cached = cache.get_current_environment()
    if cached:
        return cached
    
    # Cache MISS: charger depuis DB
    weather = db.query(Weather).filter_by(is_active=True).first()
    season = get_current_season()  # Bas√© sur le mois actuel
    
    environment = {
        "weather": {
            "id": weather.id,
            "name": weather.name,
            "gathering_multiplier": float(weather.gathering_multiplier),
            "crafting_multiplier": float(weather.crafting_multiplier)
        },
        "season": {
            "id": season.id,
            "name": season.name,
            "gathering_multiplier": float(season.gathering_multiplier),
            "crafting_multiplier": float(season.crafting_multiplier)
        },
        "timestamp": datetime.utcnow().isoformat()
    }
    
    # Cacher pour 1h
    cache.set_current_environment(environment)
    
    return environment
```

### 2. Cache March√©

```python
# Route: GET /api/market/listings
@router.get("/listings")
def get_market_listings(
    resource_id: Optional[int] = None,
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # V√©rifier cache
    cached = cache.get_market_listings(resource_id=resource_id)
    if cached:
        return {"source": "cache", "listings": cached}
    
    # Cache MISS: charger depuis DB
    query = db.query(Market).filter(Market.status_id == 1)  # active
    if resource_id:
        query = query.filter(Market.resource_id == resource_id)
    
    listings = [listing.to_dict() for listing in query.all()]
    
    # Cacher pour 1min
    cache.set_market_listings(listings, resource_id=resource_id)
    
    return {"source": "database", "listings": listings}


# Route: POST /api/market/listings (cr√©er offre)
@router.post("/listings")
def create_listing(
    data: MarketListingCreate,
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # Cr√©er listing en DB
    listing = Market(**data.dict())
    db.add(listing)
    db.commit()
    
    # Invalider cache march√© pour cette ressource
    cache.invalidate_market_cache(resource_id=data.resource_id)
    
    return listing


# Route: POST /api/market/listings/{id}/buy (acheter)
@router.post("/listings/{id}/buy")
def buy_listing(
    id: int,
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # ... logique achat ...
    
    # Invalider cache
    cache.invalidate_market_cache(resource_id=listing.resource_id)
    cache.invalidate_user_inventory(buyer_id)
    cache.invalidate_user_inventory(seller_id)
    
    return {"status": "success"}
```

### 3. Cache Leaderboard

```python
# Route: GET /api/leaderboard
@router.get("/leaderboard")
def get_leaderboard(
    limit: int = 100,
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # V√©rifier cache
    cached = cache.get_leaderboard(limit=limit)
    if cached:
        return {"source": "cache", "leaderboard": cached}
    
    # Cache MISS: charger depuis DB (ou Vue Mat√©rialis√©e)
    leaderboard = db.query(mv_leaderboard).limit(limit).all()
    leaderboard_data = [row.to_dict() for row in leaderboard]
    
    # Cacher pour 5min
    cache.set_leaderboard(leaderboard_data, limit=limit)
    
    return {"source": "database", "leaderboard": leaderboard_data}


# Job p√©riodique: Refresh leaderboard (Celery ou APScheduler)
@scheduler.scheduled_job('interval', minutes=5)
def refresh_leaderboard_cache():
    cache = get_cache()
    cache.invalidate_leaderboard()
    logger.info("Leaderboard cache invalid√©")
```

### 4. Cache Inventaire

```python
# Route: GET /api/inventory
@router.get("/inventory")
def get_user_inventory(
    user: User = Depends(get_current_user),
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # V√©rifier cache
    cached = cache.get_user_inventory(user.id)
    if cached:
        return {"source": "cache", "inventory": cached}
    
    # Cache MISS
    inventory = db.query(Inventory).filter_by(user_id=user.id).all()
    inventory_data = [item.to_dict() for item in inventory]
    
    # Cacher pour 30s
    cache.set_user_inventory(user.id, inventory_data)
    
    return {"source": "database", "inventory": inventory_data}


# Route: POST /api/craft (invalide inventaire apr√®s craft)
@router.post("/craft")
def craft_item(
    data: CraftRequest,
    user: User = Depends(get_current_user),
    cache: CacheService = Depends(get_cache)
):
    # ... logique crafting ...
    
    # Invalider cache inventaire
    cache.invalidate_user_inventory(user.id)
    cache.invalidate_user_recipes(user.id)
    
    return {"status": "success"}
```

### 5. Sessions Utilisateur

```python
# Route: POST /api/auth/login
@router.post("/login")
def login(
    credentials: LoginRequest,
    cache: CacheService = Depends(get_cache),
    db: Session = Depends(get_db)
):
    # Authentifier
    user = authenticate_user(credentials.login, credentials.password, db)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    # Cr√©er session Redis
    session_id = str(uuid.uuid4())
    session_data = {
        "user_id": user.id,
        "login": user.login,
        "role": user.role,
        "created_at": datetime.utcnow().isoformat()
    }
    cache.set_session(session_id, session_data)
    
    # G√©n√©rer JWT avec session_id
    access_token = create_access_token(data={"sub": user.login, "session_id": session_id})
    
    return {"access_token": access_token, "token_type": "bearer"}


# Route: POST /api/auth/logout
@router.post("/logout")
def logout(
    user: User = Depends(get_current_user),
    session_id: str = Depends(get_session_id),
    cache: CacheService = Depends(get_cache)
):
    # Supprimer session Redis
    cache.delete_session(session_id)
    
    return {"status": "logged_out"}


# Middleware: Refresh session sur chaque requ√™te
@app.middleware("http")
async def refresh_session_middleware(request: Request, call_next):
    session_id = request.headers.get("X-Session-ID")
    if session_id:
        cache = get_cache()
        cache.refresh_session(session_id)
    
    response = await call_next(request)
    return response
```

### 6. Rate Limiting

```python
# Middleware: Rate limiting par utilisateur
@app.middleware("http")
async def rate_limit_middleware(request: Request, call_next):
    cache = get_cache()
    
    # Identifier l'utilisateur (IP ou user_id)
    identifier = request.client.host
    if hasattr(request.state, "user"):
        identifier = f"user_{request.state.user.id}"
    
    # V√©rifier rate limit (60 req/min)
    if not cache.check_rate_limit(identifier, max_requests=60, window_seconds=60):
        remaining = cache.get_remaining_requests(identifier, max_requests=60)
        raise HTTPException(
            status_code=429,
            detail=f"Rate limit exceeded. {remaining} requests remaining."
        )
    
    response = await call_next(request)
    
    # Ajouter headers informatifs
    response.headers["X-RateLimit-Limit"] = "60"
    response.headers["X-RateLimit-Remaining"] = str(cache.get_remaining_requests(identifier, 60))
    
    return response


# D√©corateur pour rate limit sp√©cifique
from functools import wraps

def rate_limit(max_requests: int = 10, window: int = 60):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache = get_cache()
            user = kwargs.get("user") or kwargs.get("current_user")
            
            identifier = f"endpoint_{func.__name__}_{user.id if user else 'anonymous'}"
            
            if not cache.check_rate_limit(identifier, max_requests, window):
                raise HTTPException(status_code=429, detail="Too many requests")
            
            return await func(*args, **kwargs)
        return wrapper
    return decorator


# Utilisation
@router.post("/craft")
@rate_limit(max_requests=10, window=60)  # Max 10 crafts/minute
async def craft_item(data: CraftRequest, user: User = Depends(get_current_user)):
    # ... logique craft ...
    pass
```

---

## üìä Monitoring & Administration

### Redis CLI (Docker)

```bash
# Acc√©der au CLI
docker exec -it bcraftd-redis redis-cli -a redis_secure_pass

# Commandes utiles
127.0.0.1:6379> PING
PONG

127.0.0.1:6379> INFO memory
# used_memory_human:45.23M

127.0.0.1:6379> DBSIZE
(integer) 1243

127.0.0.1:6379> KEYS env:*
1) "env:current"
2) "env:weather:current"

127.0.0.1:6379> GET env:current
"{\"weather\":{...}}"

127.0.0.1:6379> TTL env:current
(integer) 3456

127.0.0.1:6379> DEL market:listings:active:10
(integer) 1

127.0.0.1:6379> FLUSHDB
OK
```

### Redis Commander (UI Web)

```bash
# D√©marrer avec Docker Compose (profile tools)
docker-compose --profile tools up -d redis-commander

# Acc√©der: http://localhost:8081
# Credentials: Pas n√©cessaire (connexion directe)
```

**Fonctionnalit√©s** :
- Visualiser toutes les cl√©s
- Inspecter valeurs JSON
- Supprimer/Modifier cl√©s
- Voir TTL restant
- Statistiques temps r√©el

### Statistiques Python

```python
from services.cache_service import CacheService

cache = CacheService()

stats = cache.get_stats()
print(f"""
üìä Statistiques Redis
=====================
Clients connect√©s: {stats['connected_clients']}
M√©moire utilis√©e: {stats['used_memory_human']}
M√©moire pic: {stats['used_memory_peak_human']}
Commandes trait√©es: {stats['total_commands_processed']:,}
Hit rate: {stats['hit_rate']:.2f}%
Uptime: {stats['uptime_in_seconds'] / 3600:.1f}h
Version: {stats['redis_version']}
""")
```

---

## üéØ Strat√©gies de Cache

### 1. Cache-Aside (Lazy Loading)

**Pattern** : V√©rifier cache ‚Üí MISS ‚Üí Charger DB ‚Üí Cacher ‚Üí Retourner

```python
def get_data(key):
    # 1. V√©rifier cache
    data = cache.get(key)
    if data:
        return data  # Cache HIT
    
    # 2. Cache MISS: charger depuis DB
    data = db.query(...).first()
    
    # 3. Cacher
    cache.set(key, data, ttl=300)
    
    # 4. Retourner
    return data
```

**Avantages** :
- Simple √† impl√©menter
- Pas de donn√©es inutiles en cache
- R√©silient (DB comme source de v√©rit√©)

**Inconv√©nients** :
- Premier acc√®s lent (cold start)
- Cache stampede possible

### 2. Write-Through

**Pattern** : √âcrire en DB **ET** en cache simultan√©ment

```python
def update_data(key, data):
    # 1. √âcrire en DB
    db.update(...)
    db.commit()
    
    # 2. √âcrire en cache
    cache.set(key, data, ttl=300)
    
    return data
```

**Avantages** :
- Cache toujours √† jour
- Pas de cache MISS apr√®s √©criture

**Inconv√©nients** :
- Latence √©criture augment√©e
- Donn√©es potentiellement inutiles en cache

### 3. Write-Behind (Write-Back)

**Pattern** : √âcrire en cache ‚Üí Async ‚Üí √âcrire en DB

```python
def update_data_async(key, data):
    # 1. √âcrire en cache imm√©diatement
    cache.set(key, data, ttl=300)
    
    # 2. Queue pour √©criture DB asynchrone
    celery_task.delay(write_to_db, data)
    
    return data
```

**Avantages** :
- √âcriture ultra-rapide
- R√©duit charge DB

**Inconv√©nients** :
- Risque perte donn√©es (si Redis crash avant write)
- Complexit√© accrue

### 4. Invalidation sur √âv√©nements

**Pattern** : Invalider cache quand donn√©es changent

```python
# √âv√©nement: Nouvelle vente sur march√©
@market_bp.route("/buy", methods=["POST"])
def buy_item():
    # ... logique achat ...
    
    # Invalider caches impact√©s
    cache.invalidate_market_cache(resource_id=item.resource_id)
    cache.invalidate_user_inventory(buyer.id)
    cache.invalidate_user_inventory(seller.id)
    cache.invalidate_leaderboard()  # Si impact classement
    
    return {"status": "success"}
```

**Recommandation B-CraftD** :
- **Environnement** : Cache-Aside (change rarement)
- **March√©** : Cache-Aside + Invalidation √©v√©nements
- **Inventaire** : Invalidation stricte (coh√©rence critique)
- **Leaderboard** : TTL court (5min) + refresh p√©riodique
- **Sessions** : Write-Through (s√©curit√©)

---

## üîç Troubleshooting

### Probl√®me: "Connection refused"

```bash
# V√©rifier que Redis tourne
docker ps | grep redis

# V√©rifier les logs
docker logs bcraftd-redis

# Red√©marrer
docker-compose restart redis
```

### Probl√®me: "NOAUTH Authentication required"

```python
# V√©rifier mot de passe dans .env
REDIS_PASSWORD=redis_secure_pass

# Passer le mot de passe au CacheService
cache = CacheService(password=os.getenv("REDIS_PASSWORD"))
```

### Probl√®me: "Out of memory"

```bash
# V√©rifier m√©moire utilis√©e
docker exec bcraftd-redis redis-cli -a redis_secure_pass INFO memory

# Augmenter maxmemory dans redis.conf
maxmemory 1gb

# Ou vider le cache
docker exec bcraftd-redis redis-cli -a redis_secure_pass FLUSHDB
```

### Probl√®me: Hit Rate < 50%

**Causes possibles** :
1. TTL trop court ‚Üí Augmenter TTL
2. Trop d'invalidations ‚Üí Optimiser strat√©gie
3. Cl√©s mal con√ßues ‚Üí Revoir nomenclature
4. Donn√©es rarement consult√©es ‚Üí Ne pas cacher

**Solution** :
```python
# Monitorer hit rate
stats = cache.get_stats()
if stats['hit_rate'] < 50:
    logger.warning(f"Hit rate faible: {stats['hit_rate']:.2f}%")
    # Ajuster TTL ou strat√©gie
```

### Probl√®me: Redis lent

```bash
# V√©rifier latence
redis-cli --latency -a redis_secure_pass

# V√©rifier slow log
redis-cli -a redis_secure_pass SLOWLOG GET 10

# Optimisations:
# 1. Activer io-threads (redis.conf)
# 2. Utiliser pipeline pour bulk operations
# 3. √âviter KEYS (utiliser SCAN)
```

---

## ‚úÖ Checklist de D√©ploiement

- [ ] Redis 7.2+ d√©marr√© (Docker ou natif)
- [ ] Fichier `redis.conf` configur√© (persistence, m√©moire, s√©curit√©)
- [ ] Mot de passe Redis d√©fini (`.env`)
- [ ] `redis-py` install√© (`pip install redis==5.0.1`)
- [ ] `CacheService` int√©gr√© dans l'application
- [ ] Tests `test_cache_service.py` passent (100%)
- [ ] Monitoring configur√© (Redis Commander ou CLI)
- [ ] Backup automatique RDB/AOF configur√©
- [ ] Rate limiting activ√© sur API
- [ ] Logs Python configur√©s (niveau INFO)
- [ ] Hit rate > 70% apr√®s 1 semaine

---

## üìö Ressources

- [Documentation Redis](https://redis.io/docs/)
- [redis-py Documentation](https://redis-py.readthedocs.io/)
- [Redis Best Practices](https://redis.io/docs/manual/patterns/)
- [Caching Strategies](https://redis.io/docs/manual/patterns/distributed-locks/)

---

**Phase 3 compl√©t√©e** ‚úÖ  
**Prochaine √©tape** : Phase 4 - Mod√®les SQLAlchemy

---

**Date de derni√®re mise √† jour** : 4 d√©cembre 2025